---
title: "Prospectus"
date-modified: today
date-format: medium
author:
  - name: "Sicheng Wang"
    email: Wangs22@wfu.edu
    affiliation: "Wake Forest University"
abstract: |
  Biotechnology sectors have been favored by investors in recent years, but biomedical texts often contain specialized jargon and abbreviations, making them difficult to read. Previous studies on biomedical literature translation mainly targeted biomedical experts, neglecting those without such background. This paper adopts a reader-based translation approach guided by Skopos theory, which aims to translate a text for a specific purpose. As a case study, this paper translates a Nature article “Control of the Activity of CAR-T Cells within Tumors via Focused Ultrasound” from English to Chinese, targeting investors without biomedical expertise. Utilizing Wordfast to ensure accuracy, especially in translating field-specific terms, and abbreviations, this study summarizes and examines translation options to aid non-biomedical investors’ understanding. Based on Hyland's metadiscourse markers, which writers employ to aid readers' comprehension, this paper uses RStudio to count markers utilized in translation, serving as an indicator of our attempts to assist readers’ comprehension. This study serves as a starting point for exploring translation options of biomedical literature for investors without a biomedical background. To bolster these translation options’ practicability, it is suggested to expand the corpus and incorporate feedback from readers.
keywords:
  - metadiscourse marker
  - biomedical literacture translation
  - reader-oriented
  - Skopos theory
  - E-C
citation: true
bibliography: "../bibliography.bib"
format:
  html: default
  pdf:
    number-sections: true
---

# Introduction

Against the backdrop of normalized epidemic prevention and control and supported initiatives such as the “Healthy China Initiative,” the urgency and significance of China’s biopharmaceutical industry development have surged [@Sun2022]. Frost & Sullivan reported that the Chinese biopharmaceutical market ranks among the most promising in the global pharmaceutical domain. Venture capital investment has increasingly focused on the biotechnology and healthcare sectors over the past five years [@Fan2021]. Yet, the scarcity of professionals with dual expertise in biomedicine and financial investment stifles innovation in biopharmaceutical firms. Biomedical texts often contain normalization sentences loaded with specialized jargon and abbreviations [@Tian2022], posing challenges for translation [@Zhao2005]. According to @reiss1981type, biomedical texts are considered informative, primarily focused on conveying information. Previous studies have targeted biomedical texts as informative text types for translation analysis, such as @Zhang2023, who analyzed biomedical texts based on the characteristics of informative texts guard by communicative translation theory [@newmark1981approaches]. However,  biomedical texts could also be viewed as operative texts. @Ding2016 summarized translation options based on text function theory [@newmark1988textbook], suggesting that technical texts could also be seen as operative texts. The emphasis on discussing translation options in biomedical texts as informative text types is attributed to the target readers, which primarily comprises scholars, experts, and individuals in the biomedical field [@Tan2020; @Li2012; @Zheng2020]. Few studies focus on readers lacking a biomedical background. @Wang2022 targeted investors without biomedical expertise, while @Wang2020 focused on the general public, and @Pei2017 targeted customers. However, this focus is primarily on genres such as news and prescriptions. There is a gap in research focusing on readers without a biomedical background in biomedical literature. This paper aims to fill this gap by focusing on investors lacking biomedical expertise, summarizing translation options for biomedical literature through the translation of a paper published in Nature titled “Control of the Activity of CAR-T Cells within Tumours via Focused Ultrasound [@wu2021control]” from English to Chinese.  The selected portion includes 3,128 words in total. The choice of this paper is driven by Acoustic Cell Therapy Inc.’s initiative, planning to commence Phase III clinical trials in China and seeking Chinese investors [@Acoustic]. Given the reader-oriented focus of this paper, Skopos theory is used as a guiding framework, aiming to translate a text for a specific purpose and target readers in a particular setting [@du2012brief]. To showcase the efficacy of the translation methods used in this paper for enhancing readers’ understanding, Hyland's metadiscourse markers [@hyland2004metadiscourse] are utilized as a benchmark. According to @Hyland2018, metadiscourse facilitates smooth communication, improves text readability, and fosters reader engagement. Earlier studies revealed that metadiscourse bolsters the propositional content of discourse and enhances its readability [@shi2014research]. @hyland2004metadiscourse emphasized that metadiscourse serves as a bridge between text and readers. @hyland2004disciplinary categorizes metadiscourse into two main types: interactive and interactional. Interactive metadiscourse guides readers through the text based on the writer's interpretations. Interactional metadiscourse, on the other hand, involves the writer more directly in conveying information to the readers. Interactive resources encompass various elements such as transitions (establishing relationships between sentences), frame markers (structuring sequences), endophoric markers (referring to information within the text), evidentials (citing other authorities), and code glosses (rephrasing for clarity). Interactional resources include hedges (introducing vagueness), boosters (emphasizing), attitude markers (indicating the writer's stance), engagement markers (drawing the reader's attention), and self-mentions (references to the author themselves). For translating technical jargon, we suggest to use amplification, whether it involves adding explanations directly into the text or clarifying the meaning of jargon by translating its full name. If adding explanations directly results in an overload of particles, inserting them into brackets then, to prevent disruption of the reading flow. However, for jargon with functions already explained in the source text, additional explanations are unnecessary. For jargon that appear more than twice, we suggest to provide explanations only the first time. For abbreviations, we choose to either replace them or provide explanations. Abbreviations created solely for the convenience of a single paper’s writing are replaced, while those widely used in the biomedical field have explanations added right after them. Borrowing is another option used for biomedical abbreviations' translation. According to @Liu1998, biomedical literature in China features numerous borrowed words, as modern medicine was introduced from abroad after the 18th century. Unified translations have not been established for frequently introduced terms, and English jargon abbreviations are often easier to remember than their Chinese equivalents. For long sentences, splitting them and identifying the main information are recommended. We can highlight the main idea instead of overwhelming the reader with excessive details.

## Research problem
Biomedical literature translation methods targeting on layperson especially investors.

## Research questions
Is the number of metadiscourse markers greater in the target text than in the source text?

## Research objectives
In order to suggest the translation methods used in the source text potentially facilitates readers' comprehension.

## Expected impact
An initial exploration of biomedical literature translation methods for individuals lacking a biomedical background.

# Literature review
1. @herriman2014metadiscourse compared the metadiscourse markers of English and Swedish in non-fiction texts and their translations. She discovered that transition markers increased in translation samples, reflecting translators' efforts to clarify the texts. Boosters, however, were diminished when translating from Swedish into English. Her analysis relied on metadiscourse markers' frequency and p-values calculated by the Sigil Corpus Frequency Test Wizard to highlight differences in metadiscourse markers between English and Swedish non-fiction texts and their translations.

2. @chou2023representation investigated the disparities between translated and non-translated English texts concerning interactional metadiscourse markers. They analyzed the Freiburg-LOB Corpus of British English and the Corpus of Chinese-English, obtaining frequency scores of metadiscourse markers via the Authorial Voice Analyzer. Their findings revealed that translated texts use fewer hedges, boosters, and attitude markers.

3. @davtalab2012contrastive focused on selected texts from an academic book to examine the contrast between metadiscourse markers in English and Persian. They utilized Anova tests and t-tests to identify significant differences between the metadiscourse markers in both languages. Their analysis concluded that there is no significant difference in metadiscourse markers between English and Persian. 

# Methods

The work flow:

![Procedure](work_flow.png)

The ideal data should be: 

```{r}
#| label: idealized-tibble
#| message: false

library(tibble) # creating tibble

idealized_tbl <- tibble(
  category = c("hedges", "boosters", "attitude marker", "engagement markers", "self-mentions", "transitions", "frame markers", "endophoric markers", "code glosses"),
  num_EN = c("*", "*", "*", "*", "*", "*", "*", "*", "*"),
  num_CN = c("*", "*", "*", "*", "*", "*", "*", "*", "*")
)

idealized_tbl
```

I have both the translated text and the source text, and I intend to read them into R for storage in `.csv` format. 

```{r}
#| label: read-csv
#| message: false

ST_txt <-
read.csv("data/derived/CAR_ST_curated.csv")

TT_txt <- read.csv("data/derived/CAR_TT_curated.csv")

ST_txt

TT_txt
```

The issue lies in the absence of labels for rows under `hedges`, `boosters`, `attitude markers`, `engagement markers`, and `self-mentions`, which should be categorized as `interactional resources`, and for rows under `transitions`, `frame markers`, `endophoric markers`, and `code glosses`, which should be labeled as `interactive resources`. However, I got an erro `Error in if (kable_format %in% c("pipe", "markdown")) { : argument is of length zero`.

## Data Preparation

### Acquisition

Read files

```{r}
#| label: read-texts
#| message: false

# Load packages
library(readr) # writing and reading data
library(dplyr) # manipulating data
library(fs) # interacting with file system
library(qtalrkit) # to generate a `data_origin` file
library(stringr)      # match words 
library(knitr)        # for `kable()` function
library(kableExtra)   # creating formatted tables

CAR_ST_lines <-
  read_lines("data/original/CAR_ST.txt") # reading the text by lines

file_cn <- "data/original/CAR_TT.txt"

Encoding(file_cn) <- "UTF-8"

CAR_TT_lines <-
  read_lines(file_cn) # reading the text by lines
```

Write files into `.csv`.

```{r}
#| label: write-files-csv.
#| message: false

CAR_ST_lines_df <-
  tibble(
  type = "Source",
  lines = CAR_ST_lines
  ) |> mutate (
  sentence_id = row_number()
  )

CAR_TT_lines_df <-
  tibble(
  type = "Target",
  lines = CAR_TT_lines
  ) |> mutate (
  sentence_id = row_number()
  )

if(!file.exists("data/original/CAR_ST.csv")){
  write_csv(CAR_ST_lines_df,
  file = "data/original/CAR_ST.csv")}

if(!file.exists("data/original/CAR_TT.csv")){write_csv(CAR_TT_lines_df,
  file = "data/original/CAR_TT.csv")}
```

### Curation

Tidy

```{r}
#| label: tidy-data
#| message: false

CAR_ST_lines_df <-
  CAR_ST_lines_df |>
  select(
  sentence_id,
  type,
  lines
  )

CAR_TT_lines_df <-
  CAR_TT_lines_df |>
  select(
  sentence_id,
  type,
  lines
  )
```

### Transformation

1. Read files

```{r}
#| label: read-raw-files
#| message: false

ST_df <-
  read_csv("data/derived/CAR_ST_curated.csv")

TT_df <-
  read_csv("data/derived/CAR_TT_curated.csv")
```

2. Counting metadiscourse markers

a. hedges

For English hedges' number

```{r}
#| label: match-hedges-en
#| message: false

hedg_may_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Mm]ay\\b.*")) |>
  summarise(num_sentences = n())

hedg_typ_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Tt]ypically\\b.*")) |>
  summarise(num_sentences = n())

hedg_rel_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Rr]elatively\\b.*")) |>
  summarise(num_sentences = n())

hedg_sli_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]lightly\\b.*")) |>
  summarise(num_sentences = n())

hedg_pro_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Pp]robably\\b.*")) |>
  summarise(num_sentences = n())

hedg_sug_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]uggest.*\\b.*")) |>
  summarise(num_sentences = n())

hedges_num_EN = hedg_may_num + hedg_typ_num + hedg_rel_num + hedg_sli_num + hedg_pro_num + hedg_sug_num
```

For Mandarin hedges' number

```{r}
#| label: match-hedges-cn
#| message: false

hedg_yi_num <- 
  TT_df |>
 filter(str_detect(lines, ".*一定程度.*")) |>
  summarise(num_sentences = n())

hedg_ke_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\可能.*")) |>
  summarise(num_sentences = n())

hedg_ji_num <- 
  TT_df |>
 filter(str_detect(lines, ".*几乎.*")) |>
  summarise(num_sentences = n())

hedg_ky_num <- 
  TT_df |>
 filter(str_detect(lines, ".*可以说是.*")) |>
  summarise(num_sentences = n())

hedg_l_num <- 
  TT_df |>
 filter(str_detect(lines, ".*略有.*")) |>
  summarise(num_sentences = n())

hedges_num_CN = hedg_yi_num + hedg_ke_num + hedg_ji_num + hedg_ky_num + hedg_l_num
```

b. boosters

For English boosters' number

```{r}
#| label: match-boosters-en
#| message: false

bo_es_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ee]specially\\b.*")) |>
  summarise(num_sentences = n())

bo_su_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]ubstantially\\b.*")) |>
  summarise(num_sentences = n())

bo_si_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]ignificantly\\b.*")) |>
  summarise(num_sentences = n())

bo_dr_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Dd]ramatically\\b.*")) |>
  summarise(num_sentences = n())

bo_pr_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Pp]recisely\\b.*")) |>
  summarise(num_sentences = n())

bo_me_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Mm]erely\\b.*")) |>
  summarise(num_sentences = n())

bo_pa_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Pp]articularly\\b.*")) |>
  summarise(num_sentences = n())

bo_in_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ii]n\\s*particular\\b.*")) |>
  summarise(num_sentences = n())

bo_ve_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Vv]ery\\b.*")) |>
  summarise(num_sentences = n())

bo_wi_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ww]ithout\\s*any\\b.*")) |>
  summarise(num_sentences = n())

bo_de_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Dd]emonstrate.*\\b.*")) |>
  summarise(num_sentences = n())

bo_ind_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ii]ndicate.*\\b.*")) |>
  summarise(num_sentences = n())

bo_ver_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Vv]erif.*\\b.*")) |>
  summarise(num_sentences = n())

boosters_num_EN = bo_es_num + bo_su_num + bo_si_num +bo_dr_num + bo_pr_num + bo_me_num + bo_pa_num + bo_in_num + bo_ve_num + bo_wi_num + bo_de_num + bo_ind_num + bo_ver_num
```

For Mandarin boosters' number

```{r}
#| label: match-boosters-cn
#| message: false

bo_bh_num <- 
  TT_df |>
 filter(str_detect(lines, ".*不会.*")) |>
  summarise(num_sentences = n())

bo_wf_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\无法.*")) |>
  summarise(num_sentences = n())

bo_bz_num <- 
  TT_df |>
 filter(str_detect(lines, ".*不再.*")) |>
  summarise(num_sentences = n())

bo_wx_num <- 
  TT_df |>
 filter(str_detect(lines, ".*无需.*")) |>
  summarise(num_sentences = n())

bo_bd_num <- 
  TT_df |>
 filter(str_detect(lines, ".*不对.*")) |>
  summarise(num_sentences = n())

bo_jb_num <- 
  TT_df |>
 filter(str_detect(lines, ".*均不.*")) |>
  summarise(num_sentences = n())

bo_gs_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\更是.*")) |>
  summarise(num_sentences = n())

bo_bx_num <- 
  TT_df |>
 filter(str_detect(lines, ".*必需.*")) |>
  summarise(num_sentences = n())

bo_jn_num <- 
  TT_df |>
 filter(str_detect(lines, ".*就能.*")) |>
  summarise(num_sentences = n())

bo_rh_num <- 
  TT_df |>
 filter(str_detect(lines, ".*任何.*")) |>
  summarise(num_sentences = n())

bo_dd_num <- 
  TT_df |>
 filter(str_detect(lines, ".*大大.*")) |>
  summarise(num_sentences = n())

bo_yq_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\尤其.*")) |>
  summarise(num_sentences = n())

bo_zy_num <- 
  TT_df |>
 filter(str_detect(lines, ".*只有.*")) |>
  summarise(num_sentences = n())

bo_j_num <- 
  TT_df |>
 filter(str_detect(lines, ".*仅.*")) |>
  summarise(num_sentences = n())

bo_z_num <- 
  TT_df |>
 filter(str_detect(lines, ".*最.*")) |>
  summarise(num_sentences = n())

bo_ji_num <- 
  TT_df |>
 filter(str_detect(lines, ".*极.*")) |>
  summarise(num_sentences = n())

bo_mx_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\明显.*")) |>
  summarise(num_sentences = n())

bo_xz_num <- 
  TT_df |>
 filter(str_detect(lines, ".*显著.*")) |>
  summarise(num_sentences = n())

bo_zs_num <- 
  TT_df |>
 filter(str_detect(lines, ".*证实.*")) |>
  summarise(num_sentences = n())

bo_js_num <- 
  TT_df |>
 filter(str_detect(lines, ".*揭示.*")) |>
  summarise(num_sentences = n())

bo_zm_num <- 
  TT_df |>
 filter(str_detect(lines, ".*证明.*")) |>
  summarise(num_sentences = n())

bo_yz_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\验证.*")) |>
  summarise(num_sentences = n())

bo_bcz_num <- 
  TT_df |>
 filter(str_detect(lines, ".*不存在.*")) |>
  summarise(num_sentences = n())

boosters_num_CN = bo_bh_num + bo_wf_num + bo_bz_num + bo_wx_num + bo_bd_num + bo_jb_num + bo_gs_num + bo_bx_num + bo_jn_num + bo_rh_num + bo_dd_num + bo_yq_num + bo_zy_num + bo_j_num + bo_z_num + bo_ji_num + bo_mx_num + bo_zs_num + bo_js_num + bo_zm_num + bo_yz_num + bo_bcz_num
```

c. attitude markers

For English attitude markers' number

```{r}
#| label: match-attitude-markers-en
#| message: false

att_dif_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Dd]ifficult\\b.*")) |>
  summarise(num_sentences = n())

att_sig_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]ignificant\\b.*")) |>
  summarise(num_sentences = n())

attitude_num_EN = att_dif_num + att_sig_num
```

For Mandarin attitude markers' number

```{r}
#| label: match-attitude -markers-cn
#| message: false

att_yw_num <- 
  TT_df |>
 filter(str_detect(lines, ".*有望.*")) |>
  summarise(num_sentences = n())

att_n_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\难.*")) |>
  summarise(num_sentences = n())

attitude_num_CN = att_yw_num + att_n_num
```

d. engagement markers

For English engagement markers' number

```{r}
#| label: match-engagement-markers-en
#| message: false

eng_gi_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Gg]iven\\b.*")) |>
  summarise(num_sentences = n())

engagement_num_EN = eng_gi_num
```

For Mandarin engagement markers' number

```{r}
#| label: match-engagement -markers-cn
#| message: false

eng_sm_num <- 
  TT_df |>
 filter(str_detect(lines, ".*说明.*")) |>
  summarise(num_sentences = n())

engagement_num_CN = eng_sm_num
```

e. self-mentions

For English self-mentions' number

```{r}
#| label: match-self-mentions-en
#| message: false

sel_we_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ww]e\\b.*")) |>
  summarise(num_sentences = n())

sel_ou_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Oo]ur\\b.*")) |>
  summarise(num_sentences = n())

self_num_EN = sel_we_num + sel_ou_num
```

For Mandarin self-mentions' number

```{r}
#| label: match-self-mentions-cn
#| message: false

sel_wm_num <- 
  TT_df |>
 filter(str_detect(lines, ".*我们.*")) |>
  summarise(num_sentences = n())

self_num_CN = sel_wm_num
```

f. transitions

For English transitions' number

```{r}
#| label: match-transitions-en
#| message: false

tr_ho_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Hh]owever\\b.*")) |>
  summarise(num_sentences = n())

tr_wh_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ww]hile\\b.*")) |>
  summarise(num_sentences = n())

tr_bu_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Bb]ut\\b.*")) |>
  summarise(num_sentences = n())

tr_thu_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Tt]hus\\b.*")) |>
  summarise(num_sentences = n())

tr_in_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ii]n\\s*contrast(?:\\sto)?\\b.*")) |>
  summarise(num_sentences = n())

tr_ad_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Aa]dditionally\\b.*")) |>
  summarise(num_sentences = n())

tr_mo_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Mm]oreover\\b.*")) |>
  summarise(num_sentences = n())

tr_al_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Aa]lso\\b.*")) |>
  summarise(num_sentences = n())

tr_st_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ss]till\\b.*")) |>
  summarise(num_sentences = n())

tr_the_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Tt]herefore\\b.*")) |>
  summarise(num_sentences = n())

tr_as_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Aa]s\\s*such\\b.*")) |>
  summarise(num_sentences = n())

tr_an_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Aa]nd\\b.*")) |>
  summarise(num_sentences = n())

transitions_num_EN = tr_ho_num + tr_wh_num + tr_bu_num + tr_thu_num + tr_in_num + tr_ad_num + tr_mo_num + tr_al_num + tr_st_num + tr_the_num + tr_as_num + tr_an_num 
```

For Mandarin transitions' number

```{r}
#| label: match-transitions-cn
#| message: false

tr_d_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\但.*")) |>
  summarise(num_sentences = n())

tr_re_num <- 
  TT_df |>
 filter(str_detect(lines, ".*然而.*")) |>
  summarise(num_sentences = n())

tr_e_num <- 
  TT_df |>
 filter(str_detect(lines, ".*而.*")) |>
  summarise(num_sentences = n())

tr_sr_num <- 
  TT_df |>
 filter(str_detect(lines, ".*虽然.*")) |>
  summarise(num_sentences = n())

tr_ds_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\但是.*")) |>
  summarise(num_sentences = n())

tr_q_num <- 
  TT_df |>
 filter(str_detect(lines, ".*且.*")) |>
  summarise(num_sentences = n())

tr_ce_num <- 
  TT_df |>
 filter(str_detect(lines, ".*从而.*")) |>
  summarise(num_sentences = n())

tr_rc_num <- 
  TT_df |>
 filter(str_detect(lines, ".*如此.*")) |>
  summarise(num_sentences = n())

tr_yy_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\由于.*")) |>
  summarise(num_sentences = n())

tr_zy_num <- 
  TT_df |>
 filter(str_detect(lines, ".*这样一来.*")) |>
  summarise(num_sentences = n())

tr_yw_num <- 
  TT_df |>
 filter(str_detect(lines, ".*因为.*")) |>
  summarise(num_sentences = n())

tr_sy_num <- 
  TT_df |>
 filter(str_detect(lines, ".*所以.*")) |>
  summarise(num_sentences = n())

tr_yc_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\因此.*")) |>
  summarise(num_sentences = n())

tr_sh_num <- 
  TT_df |>
 filter(str_detect(lines, ".*随后.*")) |>
  summarise(num_sentences = n())

tr_rg_num <- 
  TT_df |>
 filter(str_detect(lines, ".*如果.*")) |>
  summarise(num_sentences = n())

tr_r_num <- 
  TT_df |>
 filter(str_detect(lines, ".*若.*")) |>
  summarise(num_sentences = n())

tr_h_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\或.*")) |>
  summarise(num_sentences = n())

tr_ts_num <- 
  TT_df |>
 filter(str_detect(lines, ".*同时.*")) |>
  summarise(num_sentences = n())

tr_yj_num <- 
  TT_df |>
 filter(str_detect(lines, ".*以及.*")) |>
  summarise(num_sentences = n())

tr_ren_num <- 
  TT_df |>
 filter(str_detect(lines, ".*仍.*")) |>
  summarise(num_sentences = n())

tr_he_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\和.*")) |>
  summarise(num_sentences = n())

tr_y_num <- 
  TT_df |>
 filter(str_detect(lines, ".*也.*")) |>
  summarise(num_sentences = n())

tr_xb_num <- 
  TT_df |>
 filter(str_detect(lines, ".*相比.*")) |>
  summarise(num_sentences = n())

tr_bin_num <- 
  TT_df |>
 filter(str_detect(lines, ".*并.*")) |>
  summarise(num_sentences = n())

transitions_num_CN = tr_d_num + tr_re_num + tr_e_num + tr_sr_num + tr_ds_num + tr_q_num + tr_ce_num + tr_rc_num + tr_yy_num + tr_zy_num + tr_yw_num + tr_sy_num + tr_yc_num + tr_sh_num + tr_rg_num + tr_r_num + tr_h_num + tr_ts_num + tr_yj_num + tr_ren_num + tr_he_num + tr_y_num + tr_xb_num + tr_bin_num
```

g. frame markers

For English frame markers' number

```{r}
#| label: match-frame-markers-en
#| message: false

fr_fi_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ff]irst.*\\b.*")) |>
  summarise(num_sentences = n())

fr_th_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Tt]hen\\b.*")) |>
  summarise(num_sentences = n())

fr_fu_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ff]urther\\b.*")) |>
  summarise(num_sentences = n())

fr_re_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Rr]ecently\\b.*")) |>
  summarise(num_sentences = n())

fr_he_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Hh]ere\\b.*")) |>
  summarise(num_sentences = n())

fr_ta_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Tt]aken\\s*together\\b.*")) |>
  summarise(num_sentences = n())

frame_num_EN = fr_fi_num + fr_th_num +fr_fu_num + fr_re_num + fr_he_num + fr_ta_num
```

For Mandarin frame markers' number

```{r}
#| label: match-frame-markers-cn
#| message: false

fr_sx_num <- 
  TT_df |>
 filter(str_detect(lines, ".*首先.*")) |>
  summarise(num_sentences = n())

fr_xs_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\先是.*")) |>
  summarise(num_sentences = n())

fr_dc_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\第.次.*")) |>
  summarise(num_sentences = n())

fr_zs_num <- 
  TT_df |>
 filter(str_detect(lines, ".*这是.*")) |>
  summarise(num_sentences = n())

fr_db_num <- 
  TT_df |>
 filter(str_detect(lines, ".*第.部分.*")) |>
  summarise(num_sentences = n())

fr_jb_num <- 
  TT_df |>
 filter(str_detect(lines, ".*进一步.*")) |>
  summarise(num_sentences = n())

frame_num_CN = fr_sx_num + fr_xs_num + fr_dc_num + fr_zs_num + fr_db_num + fr_jb_num
```

h. endophoric markers

For English endophoric markers' number

```{r}
#| label: match-endophoric markers-en
#| message: false

end_fi_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ff]ig\\b.*")) |>
  summarise(num_sentences = n())

end_vi_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Vv]ideo\\b.*")) |>
  summarise(num_sentences = n())

end_me_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\bMethods\\b.*")) |>
  summarise(num_sentences = n())

end_as_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Aa]s\\s*describe.*\\b.*")) |>
  summarise(num_sentences = n())

endophoric_num_EN = end_fi_num + end_vi_num + end_me_num + end_as_num
```

For Mandarin endophoric markers' number

```{r}
#| label: match-endophoric -markers-cn
#| message: false

end_jt_num <- 
  TT_df |>
 filter(str_detect(lines, ".*见图.*")) |>
  summarise(num_sentences = n())

end_ru_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\如图.*")) |>
  summarise(num_sentences = n())

end_bc_num <- 
  TT_df |>
 filter(str_detect(lines, ".*补充数据图.*")) |>
  summarise(num_sentences = n())

end_flt_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\附录图.*")) |>
  summarise(num_sentences = n())

end_js_num <- 
  TT_df |>
 filter(str_detect(lines, ".*技术原理部分.*")) |>
  summarise(num_sentences = n())

end_fa_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\方案.*")) |>
  summarise(num_sentences = n())

end_sp_num <- 
  TT_df |>
 filter(str_detect(lines, ".*附录视频.*")) |>
  summarise(num_sentences = n())

end_ss_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\上述.*")) |>
  summarise(num_sentences = n())

end_xq_num <- 
  TT_df |>
 filter(str_detect(lines, ".*先前.*")) |>
  summarise(num_sentences = n())

endophoric_num_CN = end_jt_num + end_ru_num + end_bc_num + end_flt_num + end_js_num + end_fa_num + end_sp_num + end_ss_num + end_xq_num
```

i. code glosses

For English code glosses' number

```{r}
#| label: match-code-glosses-en
#| message: false

co_fo_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ff]or\\s*instance\\b.*")) |>
  summarise(num_sentences = n())

co_in_num <- 
  ST_df |>
 filter(str_detect(lines, ".*\\b[Ii]ncluding\\b.*")) |>
  summarise(num_sentences = n())

code_num_EN = co_fo_num + co_in_num
```

For Mandarin code glosses' number

```{r}
#| label: match-code-glosses-cn
#| message: false

co_j_num <- 
  TT_df |>
 filter(str_detect(lines, ".*即.*")) |>
  summarise(num_sentences = n())

co_g_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\该.*")) |>
  summarise(num_sentences = n())

co_qz_num <- 
  TT_df |>
 filter(str_detect(lines, ".*其中.*")) |>
  summarise(num_sentences = n())

co_bk_num <- 
  TT_df |>
 filter(str_detect(lines, ".*\\包括.*")) |>
  summarise(num_sentences = n())

code_num_CN = co_j_num + co_g_num + co_qz_num + co_bk_num
```

3. Metadiscourse marker tibble

```{r}
#| label: create-metadiscourse-tibble
#| message: false

meta_tbl <- tibble(
  Category = c("hedges", "boosters",  "attitude markers", "engagement markers", "self-mentions", "transitions", "frame markers", "endophoric markers", "code glosses"),
  Num_EN = c(as.numeric(hedges_num_EN), as.numeric(boosters_num_EN),  as.numeric(attitude_num_EN), as.numeric(engagement_num_EN), as.numeric(self_num_EN), as.numeric(transitions_num_EN), as.numeric(frame_num_EN), as.numeric(endophoric_num_EN), as.numeric(code_num_EN)),
  Num_CN = c(as.numeric(hedges_num_CN), as.numeric(boosters_num_CN), as.numeric(attitude_num_CN), as.numeric(engagement_num_CN), as.numeric(self_num_CN), as.numeric(transitions_num_CN), as.numeric(frame_num_CN), as.numeric(endophoric_num_CN), as.numeric(code_num_CN))
) 
```

```{r}
#| label: read-transformed-csv
#| message: false
#| echo: false

trans_tbl <-
read.csv("data/derived/meta_num.csv")

trans_tbl
```

## Data Analysis

Based on my inquiry, `Is the number of metadiscourse markers greater in the target text than in the source text?`, my analysis is focused on inferential analysis and univariate analysis by comparing the mean. With a dataset transformed to contain the number of metadiscourse markers in both the source and target texts, I plan to compare them by category to calculate the `p-value` and `confidence interval`. The null hypothesis posits that there is no difference in metadiscourse markers between the target and source texts. The alternative hypothesis is that the number of metadiscourse markers in the target text is greater  than ones in the source text. 

### Load packages

```{r}
#| label: load-packages
#| message: false

# Load packages
library(tidytext)     # text manipulation
library(ggplot2)      # plotting
library(infer)      # for statistical inference
library(skimr)      # for descriptive statistics
library(janitor)    # for cross-tabulation
```

### Read files

```{r}
#| label: read-inf-files
#| message: false

meta_inf_tbl <-
  read_csv("data/derived/meta_inf.csv")

meta__inf_tbl <-
  meta_inf_tbl |> 
  mutate(Category = factor(Category))|>
  mutate(Text_type = factor(Text_type))

meta_inf_tbl 
```

### Identify

```{r}
#| label: map-hypothesis
#| message: false

# Dataset
meta_inf_tbl 

# Specify the relationship
meta_spec <-
  meta__inf_tbl |>
  specify(Num ~ Text_type)

# Preview
meta_spec
```

### Inspect

```{r}
#| label: assess-distribution
#| message: false

# Density plot
meta_inf_tbl |>
  ggplot(aes(x = Num, fill = Text_type)) +
  geom_density(alpha = 0.75) +
  labs(
  x = "Metadiscourse markers number",
  y = "Density",
  fill = "Text type"
  )

meta__inf_tbl |>
  ggplot(aes(x = Text_type, y = Num, fill = Text_type)) +
  geom_boxplot(notch = TRUE) +
  labs(
  x = "Text type",
  y = "Metadiscourse markers number",
  fill = "Text type"
  )

ggplot(meta__inf_tbl, aes(x = Num, color = Text_type)) +
  stat_ecdf() +
  labs(
  x = "Metadiscourse markers number",
  y = "ECDF",
  color = "Text type"
  )
```

### Interrogate

#### Observed statistic

```{r}
#| label: calculate-observed-statistic
#| message: false

meta_obs <-
  meta_spec |>
  # Target Text - Source Text
  calculate(stat = "diff in means", order = c("TT", "ST"))

meta_obs
```

#### Null distribution

```{r}
#| label: generate-null-distribution
#| message: false

meta_null <-
  meta_spec |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "diff in means", order = c("TT", "ST"))

meta_null |> visualize() +
  shade_p_value(obs_stat = meta_obs, direction = "greater")
```

#### P-value

```{r}
#| label: calculate-p-value
#| message: false

meta_p <-
  meta_null |>
  get_p_value(obs_stat = meta_obs, direction = "greater")

meta_p
```

#### Resampling distribution

```{r}
#| label: generate-resampling-distribution
#| message: false

meta_boot <-
  meta_spec |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "diff in means", order = c("TT", "ST"))

meta_boot |> visualize()
```

#### Confidence interval

```{r}
#| label: calculate-confidence-interval
#| message: false

meta_ci <-
  meta_boot |>
  get_confidence_interval(level = 0.95)

meta_ci
```

### Interpret

```{r}
#| label: evaluate
#| message: false

# Evaluate the p-value
meta_p

# Evaluate the confidence interval
meta_ci

meta_boot |>
  visualize() +
  shade_confidence_interval(meta_ci)
```

# Expected results

There is no difference in metadiscourse markers between the target and source texts.

# Communication plan

For the public, I created a PowerPoint presentation and slideshows in Quarto using `reveal.js`. It contains the elements of `intro`, `literature review`, `research question`, `methods`, `findings`. Since I'm presenting to individuals outside my field, I explain the meaning of terminologies specific to our field. To share with peers, I push my repository to GitHub with `renv.lock` and `README` to ensure reproducibility. The final result is in HTML format.

# Conclusion

The translation methods we recommended did not significantly assist the comprehension of the target readers. However, it's important to note that this conclusion is based on a small dataset. Further testing with larger corpora or collaboration with target readers to gather feedback could provide more insights into the effectiveness of the translation methods. In addition, future researchers targetting on biomedical literature translation could explore alternative perspectives to enhance comprehension for the target audience.

# References

::: {#refs}
:::

# Appendix {.appendix}

![Hyland's Metadiscourse Model](meta.png)

![Hyland's Metadiscourse Model in Chinese](meta_CN.png)

```{r}
#| label: customize-meta-category
#| message: false
#| echo: false

EN_meta <- tibble(
  Category = c("hedges", "hedges", "hedges", "hedges", "hedges", "hedges", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "attitude markers", "attitude markers", "engagement markers", "self-mentions", "self-mentions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "frame markers", "frame markers", "frame markers", "frame markers", "frame markers", "frame markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "code glosses", "code glosses"),
  EN_Word = c("may", "probably", "slightly", "relatively", "suggest", "typically", "especially", "substantially", "dramatically", "significantly", "merely", "without any", "demonstrate", "indicate", "verify", "particularly", "in particular", "precisely", "very", "difficult", "significant", "given", "we", "our", "however", "while", "additionally", "and", "also", "moreover", "but", "still", "in contrast to", "in contrast", "therefore", "thus", "as such", "first", "then", "further", "here", "taken together", "recently", "Fig", "Video", "Methods", "as described above", "for instance", "including")
)

CN_meta <- tibble(
  Category = c("hedges", "hedges", "hedges", "hedges", "hedges", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "boosters", "attitude markers", "attitude markers", "engagement markers", "self-mentions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "transitions", "frame markers", "frame markers", "frame markers", "frame markers", "frame markers", "frame markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "endophoric markers", "code glosses", "code glosses", "code glosses", "code glosses"),
  CN_Word = c("可能", "几乎", "略有", "一定程度", "可以说是", "尤其", "大大", "明显", "显著", "仅", "只有", "均不", "揭示", "证明", "证实", "验证", "更是", "不会", "无法", "不再", "无需", "不对", "必需", "就能", "任何", "最", "极", "不存在", "难", "有望", "说明", "我们", "然而", "而", "同时", "且", "和", "以及", "也", "并", "但", "但是", "仍", "相比", "从而", "这样一来", "所以", "因此", "如此", "虽然", "由于", "因为", "随后", "如果", "若", "或", "首先", "先是", "进一步", "这是", "第一次/第二次", "第一部分/第二部分", "见图", "如图", "补充数据图", "附录图", "附录视频", "技术原理部分", "方案", "上述", "先前", "即", "其中", "包括", "该")
)

EN_meta
CN_meta

```
